{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd4831ad-8e5f-47fd-92f3-a9a8efcf4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For General Data Wrangling and Calculations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For NLP\n",
    "import nltk\n",
    "\n",
    "# For stop word filtering\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# For tokenizing\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "#nltk.download('punkt_tab')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "# For lemmatizing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# For TF-IDF transformation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# For Word Embedding\n",
    "import sent2vec\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# For UMAP\n",
    "import umap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f44a740-dc2b-48a0-9b28-70de7fa0a544",
   "metadata": {},
   "source": [
    "# DATA VISUALIZATION\n",
    "## 1. Distribution of number of characters in the text\n",
    "We will explore the amount of characters are found in each medical abstract pre- and post-processing of text.\n",
    "### 1.1. Pre-Processing\n",
    "Define Function to count characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9ba73-af77-4653-9995-2811231e6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_counter(data_df, counter_type, dataset_type=\"train\"):\n",
    "\n",
    "    def count_counter(text, counter_type):\n",
    "\n",
    "        # Count characters\n",
    "        if counter_type == \"char\":\n",
    "            text_length = len(text)\n",
    "\n",
    "        # Count words\n",
    "        elif counter_type == \"word\":\n",
    "            text_length = len(text.split())\n",
    "\n",
    "        # Else\n",
    "        else:\n",
    "            raise Exception(f\"Unknown counter_type {counter_type}, please choose 'char' or 'word'.\")\n",
    "\n",
    "        # Return count\n",
    "        return text_length\n",
    "\n",
    "    # Initialize a dictionary to store the character length of sentences\n",
    "    length_dict = {\n",
    "        \"neoplasms\": [],\n",
    "        \"digestive system diseases\": [],\n",
    "        \"nervous system diseases\": [],\n",
    "        \"cardiovascular diseases\": [],\n",
    "        \"general pathological conditions\": [],\n",
    "        \"total\": []\n",
    "    }\n",
    "    \n",
    "    # Initialize loop to iterate through\n",
    "    for i, row in data_df.iterrows():\n",
    "    \n",
    "        # Get cell\n",
    "        text = row[\"medical_abstract\"]\n",
    "\n",
    "        # Check dataset type\n",
    "        if dataset_type == \"train\":\n",
    "            # Get condition\n",
    "            condition = row[\"condition_name\"]\n",
    "        \n",
    "        # Check if the cell contains text\n",
    "        if isinstance(text, str):\n",
    "\n",
    "            # Get the text length\n",
    "            text_length = count_counter(text, counter_type)\n",
    "\n",
    "            # Add to the Total list in the dictionary\n",
    "            length_dict[\"total\"].append(text_length)\n",
    "\n",
    "            # Check dataset type\n",
    "            if dataset_type == \"train\":\n",
    "                # Add to the condition list in the dictionary\n",
    "                length_dict[condition].append(text_length)\n",
    "\n",
    "    # Return results\n",
    "    return length_dict if dataset_type == \"train\" else length_dict[\"total\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593e522d-9630-4fe6-ac50-6f9f8bfe7a1b",
   "metadata": {},
   "source": [
    "Define function to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4fe57-5902-4c92-a554-0eda399e922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_displot(data_dict, data_type, counter_type):\n",
    "    \"\"\"\n",
    "    Plot distribution plots of text lengths using seaborn's displot with facets.\n",
    "\n",
    "    Parameters:\n",
    "        data_dict: dict or list\n",
    "            If data_type is 'train', this should be a dictionary with conditions and total lengths.\n",
    "            If data_type is 'test', this should be a list of lengths.\n",
    "        data_type: str\n",
    "            Either 'train' or 'test\".\n",
    "    \"\"\"\n",
    "    if data_type == \"train\":\n",
    "        # Prepare the data for seaborn\n",
    "        all_data = []\n",
    "        for condition, lengths in data_dict.items():\n",
    "            all_data.extend([(condition, length) for length in lengths])\n",
    "\n",
    "        df = pd.DataFrame(all_data, columns=[\"Condition\", \"Length\"])\n",
    "\n",
    "        # Define a color palette for the conditions\n",
    "        palette = {\n",
    "            \"neoplasms\": \"#1f77b4\",\n",
    "            \"digestive system diseases\": \"#ff7f0e\",\n",
    "            \"nervous system diseases\": \"#2ca02c\",\n",
    "            \"cardiovascular diseases\": \"#d62728\",\n",
    "            \"general pathological conditions\": \"#9467bd\",\n",
    "            \"total\": \"#808080\"\n",
    "        }\n",
    "\n",
    "        # Create the facet grid with `hue` and color palette\n",
    "        g = sns.displot(\n",
    "            data=df,\n",
    "            x=\"Length\",\n",
    "            hue=\"Condition\",  # Use hue to assign colors\n",
    "            col=\"Condition\",  # Facet by condition\n",
    "            kind=\"hist\",\n",
    "            col_wrap=1,  # Ensure one plot per row\n",
    "            fill=True,\n",
    "            palette=palette,\n",
    "            legend=False\n",
    "        )\n",
    "\n",
    "        # Adjust the height while maintaining the width\n",
    "        g.set_axis_labels(\"Length\", \"Count\")\n",
    "        g.set_titles(col_template=\"{col_name}\")\n",
    "        plt.suptitle(f\"Distributions of number of {counter_type} by Condition\", y=1.02)\n",
    "\n",
    "        # Set overall figure size\n",
    "        g.fig.set_size_inches(6, 12)  # (width, height)\n",
    "\n",
    "        # Adjust layout for spacing between plots\n",
    "        plt.tight_layout()\n",
    "\n",
    "    elif data_type == \"test\":\n",
    "        # Prepare the data for seaborn\n",
    "        df = pd.DataFrame(data_dict, columns=[\"Length\"])\n",
    "\n",
    "        # Plot the distribution\n",
    "        sns.displot(df, x=\"Length\", color = \"#808080\", kind=\"hist\", fill=True, legend=False)\n",
    "\n",
    "        # Set titles and labels\n",
    "        plt.xlabel(\"Length\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(f\"Distributions of number of {counter_type} by Condition in Test Data\")\n",
    "\n",
    "        # Set figure size\n",
    "        plt.gcf().set_size_inches(6, 4)  # (width, height)\n",
    "\n",
    "        # Adjust layout for spacing between plots\n",
    "        plt.tight_layout()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid data_type. Must be 'train' or 'test'.\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c592c5d7-c5d9-4efb-8919-5f4218255e25",
   "metadata": {},
   "source": [
    "### 1.2. Plot\n",
    "Get character length distribution of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b73241-7daf-4c5c-b6f1-9740ff725650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training lemmatized data\n",
    "train_raw_len = text_counter(train_df, \"char\")\n",
    "# Testing lemmatized data\n",
    "test_raw_len = text_counter(test_df, \"char\", \"test\")\n",
    "\n",
    "# Training lemmatized data\n",
    "train_lem_len = text_counter(train_lemma_df, \"char\")\n",
    "# Testing lemmatized data\n",
    "test_lem_len = text_counter(test_lemma_df, \"char\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1020bf4a-e828-40be-aa98-ebcd4deaf453",
   "metadata": {},
   "source": [
    "Plot character length distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef4652-1bf6-46e0-9346-5fffd7ed0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Raw Training data\n",
    "plot_displot(train_raw_len, \"train\", \"Characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b35445-e41b-4a01-802c-d764330919d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Lemmatized Procces data\n",
    "plot_displot(train_lem_len, \"train\", \"Characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b77ab4-f66a-49dc-9e37-671c3dc54108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Raw Testing data\n",
    "plot_displot(test_raw_len, \"test\", \"Characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf01003-da43-46c6-8152-5a4658b0406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Processed Testing data\n",
    "plot_displot(test_lem_len, \"test\", \"Characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1046dc-b360-4fcd-87c6-0237e6af7279",
   "metadata": {},
   "source": [
    "## 2. Distribution of number of words in the text\n",
    "In this section, we will explore the amount of words found in each medical abstract pre- and post-processing of text.\n",
    "### 2.1. Plot\n",
    "Get number of words distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e9d063-ff4b-4c0e-aed4-01e92e2fd583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training lemmatized data\n",
    "train_raw_len = text_counter(train_df, \"word\")\n",
    "# Testing lemmatized data\n",
    "test_raw_len = text_counter(test_df, \"word\", \"test\")\n",
    "\n",
    "# Training lemmatized data\n",
    "train_lem_len = text_counter(train_lemma_df, \"word\")\n",
    "# Testing lemmatized data\n",
    "test_lem_len = text_counter(test_lemma_df, \"word\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae34ced-dd05-4d2e-be4b-7014eb162085",
   "metadata": {},
   "source": [
    "Plot number of words distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae6625-4f3a-4fb9-ba13-e54f04060641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Raw Training data\n",
    "plot_displot(train_raw_len, \"train\", \"Words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50fc4d-b4a2-4976-8b5a-57748407edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Lemmatized Procces data\n",
    "plot_displot(train_lem_len, \"train\", \"Characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9be39f5-2df3-45c3-ad9d-195f5fc192bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Raw Testing data\n",
    "plot_displot(test_raw_len, \"test\", \"Characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b017341-d7b1-42fa-a87e-45811a5d4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Processed Testing data\n",
    "plot_displot(test_lem_len, \"test\", \"Characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdcf005-a84a-436a-80bc-6d8656c37392",
   "metadata": {},
   "source": [
    "## 3. Dimensionality reduction\n",
    "### 3.1. Principal Component Analysis (PCA)\n",
    "Principal Component Analysis (PCA) is a method of dimensionality reduction that transform large datasets into smaller one that preserves most of the information from the large dataset. In this case, we will apply PCA for data visualization on the Principal Component 1 (PC1) and PC2.\n",
    "\n",
    "We will start standarizing the features and defining the PCA for 2 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c874dd-f034-455d-b830-8323391929fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the TF-IDF features\n",
    "x_train_tfidf = StandardScaler(with_mean = False).fit_transform(train_lem_tdidf)\n",
    "x_test_tfidf = StandardScaler(with_mean = False).fit_transform(test_lem_tdidf)\n",
    "\n",
    "# Standardizing the BioSentVec features\n",
    "x_train_s2v = StandardScaler().fit_transform(train_lem_vec)\n",
    "x_test_s2v = StandardScaler().fit_transform(test_lem_vec)\n",
    "\n",
    "# Define PCA\n",
    "pca = PCA(n_components = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71067d26-fbcc-4f83-9799-72f600358c27",
   "metadata": {},
   "source": [
    "Define function to plot PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75588348-cca3-4cf3-a1d7-fe1e75d4bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCA(pca_out, pca_fit, conditions, title, dataset_type):\n",
    "\n",
    "    # Create a dataframe to store data before plotting\n",
    "    pca_df = pd.DataFrame(data = pca_out, columns = [\"PC1\", \"PC2\"])\n",
    "\n",
    "    # Get Explained variance\n",
    "    exp_var_pca = pca_fit.explained_variance_ratio_\n",
    "\n",
    "    # Add condition label to df\n",
    "    if dataset_type == \"train\":\n",
    "        # Add Label\n",
    "        pca_df[\"condition_name\"] = conditions\n",
    "\n",
    "        # Define a color palette for the conditions\n",
    "        palette = {\n",
    "                \"neoplasms\": \"#1f77b4\",\n",
    "                \"digestive system diseases\": \"#ff7f0e\",\n",
    "                \"nervous system diseases\": \"#2ca02c\",\n",
    "                \"cardiovascular diseases\": \"#d62728\",\n",
    "                \"general pathological conditions\": \"#9467bd\"\n",
    "            }\n",
    "\n",
    "    # Initialize figure\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "\n",
    "    # Define titles\n",
    "    ax.set_xlabel(f\"Principal Component 1 ({round(exp_var_pca[0]*100, 2)}%)\", fontsize = 15)\n",
    "    ax.set_ylabel(f\"Principal Component 2 ({round(exp_var_pca[1]*100, 2)}%)\", fontsize = 15)\n",
    "    ax.set_title(title, fontsize = 20)\n",
    "\n",
    "    # Plot train\n",
    "    if dataset_type == \"train\":\n",
    "        for condition, color in palette.items():\n",
    "            indicesToKeep = pca_df[\"condition_name\"] == condition\n",
    "            ax.scatter(pca_df.loc[indicesToKeep, \"PC1\"],\n",
    "                       pca_df.loc[indicesToKeep, \"PC2\"],\n",
    "                       c = color,\n",
    "                       s = 15,\n",
    "                      alpha = 0.5)\n",
    "        ax.legend(palette.keys())\n",
    "\n",
    "    # Plot test\n",
    "    elif dataset_type == \"test\":\n",
    "        ax.scatter(pca_df[\"PC1\"],\n",
    "                       pca_df[\"PC2\"],\n",
    "                       s = 15,\n",
    "                      alpha = 0.5)\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c3698e-6bc4-4830-8d44-4fba78ed33f5",
   "metadata": {},
   "source": [
    "Plot PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9a285-e8bf-40a8-9ef5-9900a779b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Components from TF-IDF features\n",
    "pca_train_tfidf = pca.fit_transform(train_lem_tdidf)\n",
    "# TF-IDF Train Data\n",
    "plot_PCA(pca_train_tfidf, pca, train_df[\"condition_name\"], \"PCA from Train Dataset TF-IDF transformed\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2627efa-87da-4801-84b9-36b6e497ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Components from TF-IDF features\n",
    "pca_test_tfidf = pca.fit_transform(test_lem_tdidf)\n",
    "# TF-IDF Test Data\n",
    "plot_PCA(pca_test_tfidf, pca, None, \"PCA from Test Dataset TF-IDF transformed\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246164c-fa29-48b9-ab37-99f4780d5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Components from BioSent2Vec features\n",
    "pca_train_s2v = pca.fit_transform(train_lem_vec)\n",
    "# BioSentVec Train Data\n",
    "plot_PCA(pca_train_s2v, pca, train_df[\"condition_name\"], \"PCA from Train Dataset BioSentVec transformed\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3201c-e4e9-4c27-bcda-38b7ddcd1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Components from BioSent2Vec features\n",
    "pca_test_s2v = pca.fit_transform(test_lem_vec)\n",
    "# BioSentVec Test Data\n",
    "plot_PCA(pca_test_s2v, pca, None, \"PCA from Test Dataset BioSentVec transformed\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986835f-d5a7-4cd5-b335-1a9305b9ea91",
   "metadata": {},
   "source": [
    "## 3.2. Uniform Manifold Approximation and Projection for Dimension Reduction (UMAP)\n",
    "Define the dimensionally reductor of UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc7825-aa8e-4c34-b6f8-af4f8b999abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(random_state = 777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ce70e3-50ca-4e58-a12b-c4158255ed07",
   "metadata": {},
   "source": [
    "Define function to calculate an plot UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b7e73a-3098-4401-a71f-c392a3036369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_and_plot(data_vec, condition_name, dataset_type, title):\n",
    "    # Initialize the UMAP reducer\n",
    "    # reducer = UMAP(n_neighbors = 75, min_dist = 0.1, metric = \"euclidean\")\n",
    "    \n",
    "    # Calculate embeddings\n",
    "    embedding = reducer.fit_transform(data_vec)\n",
    "\n",
    "    # Show embedding shape\n",
    "    print(embedding.shape)\n",
    "\n",
    "    # Define a color palette for the conditions\n",
    "    palette = {\n",
    "        \"neoplasms\": \"#1f77b4\",\n",
    "        \"digestive system diseases\": \"#ff7f0e\",\n",
    "        \"nervous system diseases\": \"#2ca02c\",\n",
    "        \"cardiovascular diseases\": \"#d62728\",\n",
    "        \"general pathological conditions\": \"#9467bd\"\n",
    "    }\n",
    "\n",
    "    # Map conditions to colors\n",
    "    condition_colors = [palette[condition] for condition in condition_name]\n",
    "    print(len(condition_colors))\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(\n",
    "        embedding[:, 0],\n",
    "        embedding[:, 1],\n",
    "        c = condition_colors,\n",
    "        s = 10,  # Point size\n",
    "        alpha = 0.5  # Transparency\n",
    "    )\n",
    "    plt.gca().set_aspect(\"equal\", \"datalim\")\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel('UMAP1', fontsize=16)\n",
    "    plt.ylabel('UMAP2', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c7c14b-4d7e-43d3-8e97-c4191c297d8b",
   "metadata": {},
   "source": [
    "Plot UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b326e7-871b-49b6-923e-cfdc42eab215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data TF-IDF transformed\n",
    "umap_and_plot(train_lem_vec, train_df[\"condition_name\"], None, \"UMAP from Train Dataset TF-IDF transformed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48882fa9-3e5c-492d-8530-1be6c97a26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data TF-IDF transformed\n",
    "umap_and_plot(train_lem_vec, train_df[\"condition_name\"], None, \"UMAP from Train Dataset TF-IDF transformed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
